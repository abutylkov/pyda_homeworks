{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 1\n",
    "Скачайте с сайта https://grouplens.org/datasets/movielens/ датасет любого размера. Определите какому фильму было выставлено больше всего оценок 5.0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "American Beauty (1999)\n",
      "Wall time: 24.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import zipfile as z\n",
    "import pandas as pd\n",
    "\n",
    "zip_package = 'ml-1m.zip'\n",
    "mov_in_zip = zip_package.strip('.zip') + '/movies.dat'\n",
    "rat_in_zip = zip_package.strip('.zip') + '/ratings.dat'\n",
    "\n",
    "# создание объекта с данными (это не str, а b\"bytes\\n\", поэтому нужно перекодировать),\n",
    "with z.ZipFile(zip_package, 'r') as data_in:\n",
    "#     data_in.printdir()\n",
    "#     print(data_in.namelist())\n",
    "\n",
    "    # чтение файла с фильмами\n",
    "    with data_in.open(mov_in_zip, 'r') as m:\n",
    "        movies_list = [bytes.decode(line_, 'ISO-8859-1') for line_ in m.readlines()]\n",
    "    \n",
    "    # в pandas надо открывать файл, поэтому сохраняем в файл\n",
    "    with open('movies_list.txt', 'w', encoding='utf-8') as out_file_1:\n",
    "        out_file_1.writelines(''.join(movies_list))\n",
    "    \n",
    "    # то же самое для файла с рейтингами\n",
    "    with data_in.open(rat_in_zip, 'r') as r:\n",
    "        ratings_list = [bytes.decode(line_, 'ISO-8859-1') for line_ in r.readlines()]\n",
    "  \n",
    "    with open('ratings_list.txt', 'w', encoding='utf-8') as out_file_2:\n",
    "        out_file_2.writelines(''.join(ratings_list))\n",
    "    \n",
    "# создаем датафреймы\n",
    "with open('movies_list.txt', 'r', encoding='utf-8') as file_m:\n",
    "    dfm = pd.read_csv(file_m, sep=r'::', names = ['MovieID', 'Title', 'Genres'], engine='python')\n",
    "    \n",
    "with open('ratings_list.txt', 'r', encoding='utf-8') as file_r:\n",
    "    dfr = pd.read_csv(file_r, sep=r'::', names = ['UserID', 'MovieID', 'Rating', 'Timestamp'], engine='python')\n",
    "\n",
    "# print(dfm.head)\n",
    "# print(dfr.head)\n",
    "\n",
    "# далее надо сделать join по графе с MovieID через pd.concat\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html\n",
    "\n",
    "# или join без concat\n",
    "joined = dfr.merge(dfm, on='MovieID', how='left')\n",
    "# убрали лишние графы\n",
    "fltr_cls = joined[['Title', 'Rating']]\n",
    "# убрали лишние строки\n",
    "filtered = fltr_cls.query('Rating == 5')\n",
    "# результат\n",
    "result = filtered['Title'].value_counts().head(1)\n",
    "print(str(result).split('    ')[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 2\n",
    "По данным файла power.csv посчитайте суммарное потребление стран Прибалтики (Латвия, Литва и Эстония) категорий 4, 12 и 21 за период с 2005 по 2010 года. Не учитывайте в расчетах отрицательные значения quantity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240580.0\n",
      "Wall time: 3.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# список стран\n",
    "cntr_list = ['Lithuania', 'Latvia', 'Estonia']\n",
    "# импорт файла\n",
    "data = pd.read_csv('power.csv')\n",
    "# фильтр на строки по условиям задания\n",
    "fltr_cntrs = (data[\n",
    "                    ((data['country'] == cntr_list[0]) |\n",
    "                     (data['country'] == cntr_list[1]) |\n",
    "                     (data['country'] == cntr_list[2])) &\n",
    "                    (2005 <= data['year']) &\n",
    "                    (data['year'] <= 2010) &\n",
    "                    ((data['category'] == 4) |\n",
    "                     (data['category'] == 12) |\n",
    "                     (data['category'] == 21)) &\n",
    "                    (data['quantity'] > 0)\n",
    "                    ])\n",
    "# результат\n",
    "print(sum(fltr_cntrs['quantity']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 3 Выберите страницу любого сайта с табличными данными. Импортируйте таблицы в pandas dataframe. Примеры страниц (необязательно брать именно эти): https://fortrader.org/quotes https://www.finanz.ru/valyuty/v-realnom-vremeni\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Время работы инспекции</th>\n",
       "      <th>Перерыв</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ПН</td>\n",
       "      <td>9:00-18:00</td>\n",
       "      <td>13:00-13:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ВТ</td>\n",
       "      <td>9:00-18:00</td>\n",
       "      <td>13:00-13:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>СР</td>\n",
       "      <td>9:00-18:00</td>\n",
       "      <td>13:00-13:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ЧТ</td>\n",
       "      <td>9:00-18:00</td>\n",
       "      <td>13:00-13:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ПТ</td>\n",
       "      <td>9:00-16:45</td>\n",
       "      <td>13:00-13:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ВС</td>\n",
       "      <td>не работает</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0 Время работы инспекции      Перерыв\n",
       "0         ПН             9:00-18:00  13:00-13:45\n",
       "1         ВТ             9:00-18:00  13:00-13:45\n",
       "2         СР             9:00-18:00  13:00-13:45\n",
       "3         ЧТ             9:00-18:00  13:00-13:45\n",
       "4         ПТ             9:00-16:45  13:00-13:45\n",
       "5         ВС            не работает          NaN"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mifns9 = pd.read_html('https://www.nalog.gov.ru/rn77/about_fts/fts/structure_fts/mri_fns/mi_kn_9/', encoding='utf-8')\n",
    "mifns9[0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
